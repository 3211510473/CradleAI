**目标：**

缓解长对话中 LLM（大型语言模型）记忆衰退问题，提高对话质量和连贯性，并减少上下文长度。

**解决方案：**

在`SettingsSidebar.tsx`中开启记忆总结功能，并进行设置（取代原有的“永久记忆”的位置），该功能在聊天记录文本量达到一定阈值时自动触发，对聊天记录进行总结，并将总结信息插入到聊天记录中，从而让 LLM 能够更好地回忆之前的对话内容。

**背景：**

根据 LLM 的注意力机制，模型通常对聊天记录的开头和结尾部分更加敏感，而对中间部分的信息容易遗忘。 尤其是在上下文长度非常大时，这种现象尤为明显。

**工作原理：**

1.  **触发机制：** 当聊天记录中的文本量（字符数或 Token 数）达到用户设定的“总结阈值”时，插件自动触发。
2.  **总结范围：** 抽取聊天记录的中间部分文本进行总结，总结完成后，这部分被抽取的文本将被替换为总结内容。 
3.  **总结生成：** 使用 LLM 对抽取的文本进行概括和提炼，生成一份简短的总结。
4.  **总结插入：** 将生成的总结信息以特定的格式（例如，用 `--- 总结 ---` 分隔符包裹）插入回聊天记录的中间位置。
5.  **对LLM透明:** 插入的总结对于用户是不可见的，只有LLM在读取全部消息的时候才能看到。

**用户可配置选项：**

*   **总结阈值：** 触发总结操作所需的聊天记录文本量。 用户可以根据自己的需求调整该值（例如，以字符数、单词数或 Token 数为单位）。
*   **总结长度：** 生成总结的最大字数（或 Token 数）。 较长的总结包含更多信息，但会占用更多上下文空间。 较短的总结更简洁，但可能丢失一些细节。


**注意事项：**

*   **总结内容要求：**
    *   **关键信息提取：** 确保总结准确捕捉到对话中的关键信息，例如人物、事件、目标、约定等。
    *   **指代消解：** 避免在总结中使用模糊的指代词，尽量使用明确的名称或描述。
    *   **信息关联：** 总结应该体现出上下文之间的联系，而不是简单地罗列信息点。
*   **对用户体验的影响：**
    *   **尽量减少对用户体验的影响：** 总结过程单独调用API请求，不影响用户对话的进行。
*   **API调用：** 和用户聊天所使用的API provider与apikey保持完全一致。

**优点：**

*   **缓解记忆衰退：** 帮助 LLM 更好地回忆对话内容，提高回复质量。
*   **减少上下文长度：** 通过提炼信息，用总结替换了聊天记录中间的文本，缩短了聊天记录的长度，降低计算成本，并提高 LLM 的处理效率。
*   **提高对话连贯性：** 确保 LLM 在长对话中始终掌握关键信息，保持对话主题的连贯性。